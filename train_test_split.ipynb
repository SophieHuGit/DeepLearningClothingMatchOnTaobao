{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load the packages\n",
    "from pyimagesearch import config\n",
    "from pyimagesearch import top\n",
    "from pyimagesearch.resnet import ResNet\n",
    "from imutils import paths\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Item Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>155</td>\n",
       "      <td>[123950,53517,106068,59598,7503,171811,25618,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>228</td>\n",
       "      <td>[73035,33202,116593,48909,92233,181255,127004,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>284</td>\n",
       "      <td>[123950,38910,22837,5026,15459,47776,158346,10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>461</td>\n",
       "      <td>[122071,35420,123950,27207,116593,24893,31897,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>368</td>\n",
       "      <td>[48909,125706,116593,179606,20819,158346,15722...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  item_id cat_id                                              terms\n",
       "0      29    155  [123950,53517,106068,59598,7503,171811,25618,1...\n",
       "1      49    228  [73035,33202,116593,48909,92233,181255,127004,...\n",
       "2      59    284  [123950,38910,22837,5026,15459,47776,158346,10...\n",
       "3     109    461  [122071,35420,123950,27207,116593,24893,31897,...\n",
       "4     119    368  [48909,125706,116593,179606,20819,158346,15722..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import item\n",
    "items = pd.read_csv(\"data/Taobao Clothes Matching Data/dim_itemsï¼ˆnew).txt\", sep='delimiter', header=None)\n",
    "items = items[0].apply(lambda x: x.split())\n",
    "item_df = pd.DataFrame()\n",
    "item_df['item_id'] = items.apply(lambda x: x[0])\n",
    "item_df['cat_id'] = items.apply(lambda x: x[1])\n",
    "item_df['terms'] = items.apply(lambda x: x[2:])\n",
    "item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499983, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of categories\n",
    "item_df.cat_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368    59380\n",
       "52     41859\n",
       "284    32080\n",
       "461    28388\n",
       "111    27604\n",
       "505    19985\n",
       "48     19348\n",
       "155    17720\n",
       "228    17617\n",
       "160    15930\n",
       "137    15735\n",
       "33     15638\n",
       "42     15003\n",
       "516    13285\n",
       "50     12451\n",
       "Name: cat_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cat = item_df.cat_id.value_counts()[:15]\n",
    "top_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352023, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_item_df = item_df.loc[item_df.cat_id.isin(top_cat.index), ['item_id', 'cat_id']]\n",
    "top_item_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_item = list(top_item_df.item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for items in the top 20 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the path to the *original* input directory of images\n",
    "ORIG_INPUT_DATASET = 'data/tianchi_fm_img2_1'\n",
    "\n",
    "# initialize the base path to the *new* directory that will contain our images after computing the training and testing split\n",
    "BASE_PATH = 'data'\n",
    "\n",
    "# filter path\n",
    "FILTER_PATH = os.path.sep.join([BASE_PATH, 'filter'])\n",
    "\n",
    "# create the directory\n",
    "if not os.path.exists(top.FILTER_PATH):\n",
    "        print(\"[INFO] 'creating {}' directory\".format(top.FILTER_PATH))\n",
    "        os.makedirs(top.FILTER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input image paths\n",
    "imagePaths = list(paths.list_images(config.ORIG_INPUT_DATASET))\n",
    "\n",
    "for inputPath in imagePaths:\n",
    "\n",
    "    # extract the filename of the input image along with its corresponding class label\n",
    "    filename = inputPath.split(os.path.sep)[-1]\n",
    "    file_id = filename.split('.')[0]\n",
    "    if file_id in top_item:\n",
    "        label = top_item_df.loc[top_item_df.item_id==file_id, 'cat_id'].values[0]\n",
    "        # build the path to the label directory\n",
    "        labelPath = os.path.sep.join([top.FILTER_PATH, label])\n",
    "\n",
    "        # if the label output directory does not exist, create it\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "            os.makedirs(labelPath)\n",
    "\n",
    "        # construct the path to the destination image and then copy the image itself\n",
    "        p = os.path.sep.join([labelPath, filename])\n",
    "        shutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the path to the *original* input directory of images\n",
    "ORIG_INPUT_DATASET = 'data/filter'\n",
    "\n",
    "# initialize the base path to the *new* directory that will contain our images after computing the training and testing split\n",
    "BASE_PATH = 'data'\n",
    "\n",
    "# derive the training, validation, and testing directories\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, 'training'])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, 'validation'])\n",
    "TEST_PATH = os.path.sep.join([BASE_PATH, 'testing'])\n",
    "\n",
    "# define the amount of data that will be used training\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "# the amount of validation data will be a percentage of the *training* data\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the paths to all input images in the original input directory and shuffle them\n",
    "imagePaths = list(paths.list_images(config.ORIG_INPUT_DATASET))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the training and testing split\n",
    "i = int(len(imagePaths) * config.TRAIN_SPLIT)\n",
    "trainPaths = imagePaths[:i] # 80% of the data\n",
    "testPaths = imagePaths[i:] # 20% of the data\n",
    "\n",
    "# we'll be using part of the training data for validation\n",
    "i = int(len(trainPaths) * config.VAL_SPLIT)\n",
    "valPaths = trainPaths[:i] # 8% of the data\n",
    "trainPaths = trainPaths[i:] #72% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datasets that we'll be building\n",
    "datasets = [\n",
    "    ('training', trainPaths, config.TRAIN_PATH),\n",
    "    ('validation', valPaths, config.VAL_PATH),\n",
    "    ('testing', testPaths, config.TEST_PATH)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the datasets\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "    \n",
    "    # show which data split we are creating\n",
    "    print(\"[INFO] building '{}' split\".format(dType))\n",
    "    \n",
    "    # if the output base output directory does not exist, create it\n",
    "    if not os.path.exists(baseOutput):\n",
    "        print(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "        os.makedirs(baseOutput)\n",
    "        \n",
    "    # loop over the input image paths\n",
    "    for inputPath in imagePaths:\n",
    "        \n",
    "        # extract the filename of the input image along with its corresponding class label\n",
    "        filename = inputPath.split(os.path.sep)[-1]\n",
    "        label = inputPath.split(os.path.sep)[-2]\n",
    "\n",
    "        # build the path to the label directory\n",
    "        labelPath = os.path.sep.join([baseOutput, label])\n",
    "\n",
    "        # if the label output directory does not exist, create it\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "            os.makedirs(labelPath)\n",
    "            \n",
    "        # construct the path to the destination image and then copy the image itself\n",
    "        p = os.path.sep.join([labelPath, filename])\n",
    "        shutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the total number of image paths in training, validation, and testing directories\n",
    "totalTrain = len(list(paths.list_images(config.TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(config.VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(config.TEST_PATH)))\n",
    "\n",
    "print(totalTrain)\n",
    "print(totalVal)\n",
    "print(totalTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
